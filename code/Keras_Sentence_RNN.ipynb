{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1750 speeches for 15 presidents.\n"
     ]
    }
   ],
   "source": [
    "import glob, os, json, re, unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "load_verbose = 0\n",
    "loaded_labels = []\n",
    "loaded_text = []\n",
    "labels = {\"Barack Obama\": 0,\n",
    "          \"Donald J. Trump\": 1,\n",
    "          \"Dwight D. Eisenhower\": 2,\n",
    "          \"Franklin D. Roosevelt\": 3,\n",
    "          \"George Bush\": 4,\n",
    "          \"George W. Bush\": 5,\n",
    "          \"Gerald R. Ford\": 6,\n",
    "          \"Harry S. Truman\": 7,\n",
    "          \"Herbert Hoover\": 8,\n",
    "          \"Jimmy Carter\": 9,\n",
    "          \"John F. Kennedy\": 10,\n",
    "          \"Lyndon B. Johnson\": 11,\n",
    "          \"Richard Nixon\": 12,\n",
    "          \"Ronald Reagan\": 13,\n",
    "          \"William J. Clinton\": 14}\n",
    "\n",
    "# load raw text files straight in, no parsing\n",
    "directory = \"../data/processed/\"\n",
    "file_to_label = {\"Obama\": \"Barack Obama\", \"Trump\": \"Donald J. Trump\"}\n",
    "for filename in glob.glob(os.path.join(directory, '*.txt')):\n",
    "    arr = filename.replace(directory,'').split(\"_\")\n",
    "    loaded_labels = loaded_labels + [labels[file_to_label[arr[0]]]]\n",
    "    raw = open(filename).read().decode(\"UTF-8\").encode(\"ascii\",\"ignore\")\n",
    "    loaded_text = loaded_text + [raw] \n",
    "        \n",
    "# load JSON text files; parsing into raw text\n",
    "directory = \"../data/unprocessed/\"\n",
    "for filename in glob.glob(os.path.join(directory, '*.json')):\n",
    "        json_data=open(filename)\n",
    "        data = json.load(json_data)\n",
    "        json_data.close()\n",
    "        for data2 in data[\"speeches\"]:\n",
    "            if ('News Conference With' not in data2['name']):\n",
    "                # data2['text'] has a lot of htmtl tags in there. We still need to parse it            \n",
    "                raw = BeautifulSoup(data2['text'], \"html.parser\").get_text(\" \")\n",
    "                raw = unicodedata.normalize('NFKD', raw).encode('ascii','ignore')\n",
    "                # Remove []\n",
    "                raw = re.sub(' \\[.*?\\]',' ', raw, flags=re.DOTALL)\n",
    "                # Remove ()\n",
    "                raw = re.sub(' \\(.*?\\)',' ', raw, flags=re.DOTALL)\n",
    "                # Removing the questions\n",
    "                raw = re.sub('[A-Z,\\s,\\.]Q\\..*? The President\\.','\\.',raw, flags=re.DOTALL)\n",
    "                raw = re.sub('^[A-Z,\\s]*THE PRESIDENT\\.','',raw, flags=re.DOTALL)\n",
    "                raw = re.sub('[A-Z,\\s,\\.]Q\\..*?THE PRESIDENT\\.','\\.',raw, flags=re.DOTALL)\n",
    "                \n",
    "                # capture speaker (i.e., label)\n",
    "                speaker = data2['speaker']\n",
    "                \n",
    "                # push speaker and text\n",
    "                if (load_verbose == 1):\n",
    "                    print \"Loading: \", data2['speaker'], \"(\", labels[speaker], \"), \", data2['name']\n",
    "                loaded_labels = loaded_labels + [labels[speaker]] \n",
    "                loaded_text = loaded_text + [raw]\n",
    "\n",
    "# input_text = loaded_text\n",
    "# input_labels = loaded_labels\n",
    "\n",
    "print \"Loaded\", len(loaded_text), \"speeches for\", len(set(loaded_labels)), \"presidents.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "How many speeches per president?\n",
      "0  : Barack Obama         \t152\n",
      "1  : Donald J. Trump      \t19\n",
      "2  : Dwight D. Eisenhower \t192\n",
      "3  : Franklin D. Roosevelt \t223\n",
      "4  : George Bush          \t97\n",
      "5  : George W. Bush       \t54\n",
      "6  : Gerald R. Ford       \t40\n",
      "7  : Harry S. Truman      \t301\n",
      "8  : Herbert Hoover       \t267\n",
      "9  : Jimmy Carter         \t59\n",
      "10 : John F. Kennedy      \t63\n",
      "11 : Lyndon B. Johnson    \t134\n",
      "12 : Richard Nixon        \t39\n",
      "13 : Ronald Reagan        \t46\n",
      "14 : William J. Clinton   \t64\n",
      "\n",
      "Approximately many words of text per president?\n",
      "0  : Barack Obama         \t899079\n",
      "1  : Donald J. Trump      \t87764\n",
      "2  : Dwight D. Eisenhower \t579577\n",
      "3  : Franklin D. Roosevelt \t392144\n",
      "4  : George Bush          \t354916\n",
      "5  : George W. Bush       \t322439\n",
      "6  : Gerald R. Ford       \t127862\n",
      "7  : Harry S. Truman      \t397252\n",
      "8  : Herbert Hoover       \t164674\n",
      "9  : Jimmy Carter         \t226731\n",
      "10 : John F. Kennedy      \t243153\n",
      "11 : Lyndon B. Johnson    \t425941\n",
      "12 : Richard Nixon        \t178999\n",
      "13 : Ronald Reagan        \t180653\n",
      "14 : William J. Clinton   \t332077\n",
      "\n",
      "Approximately how many average words per speech per president?\n",
      "0  : Barack Obama         \t5914\n",
      "1  : Donald J. Trump      \t4619\n",
      "2  : Dwight D. Eisenhower \t3018\n",
      "3  : Franklin D. Roosevelt \t1758\n",
      "4  : George Bush          \t3658\n",
      "5  : George W. Bush       \t5971\n",
      "6  : Gerald R. Ford       \t3196\n",
      "7  : Harry S. Truman      \t1319\n",
      "8  : Herbert Hoover       \t616\n",
      "9  : Jimmy Carter         \t3842\n",
      "10 : John F. Kennedy      \t3859\n",
      "11 : Lyndon B. Johnson    \t3178\n",
      "12 : Richard Nixon        \t4589\n",
      "13 : Ronald Reagan        \t3927\n",
      "14 : William J. Clinton   \t5188\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# summary stats & chop up into smaller\n",
    "#print \"Loaded\", len(input_text), \"speeches for\", len(set(input_labels)), \"presidents.\"\n",
    "\n",
    "print \"\\nHow many speeches per president?\"\n",
    "speech_freq = np.bincount(loaded_labels)\n",
    "for key, value in sorted(labels.iteritems()):\n",
    "    print str(value).ljust(2), \":\", key.ljust(20), \"\\t\", speech_freq[value]\n",
    "  \n",
    "print \"\\nApproximately many words of text per president?\"\n",
    "for key, value in sorted(labels.iteritems()):\n",
    "    label_set = [cnt for cnt, idx in enumerate(loaded_labels) if idx == value]\n",
    "    label_speeches = [loaded_text[i] for i in label_set]\n",
    "    print str(value).ljust(2), \":\", key.ljust(20), \"\\t\", sum(len(speech.split()) for speech in label_speeches)\n",
    "\n",
    "print \"\\nApproximately how many average words per speech per president?\"\n",
    "for key, value in sorted(labels.iteritems()):\n",
    "    label_set = [cnt for cnt, idx in enumerate(loaded_labels) if idx == value]\n",
    "    label_speeches = [loaded_text[i] for i in label_set]\n",
    "    print str(value).ljust(2), \":\", key.ljust(20), \"\\t\", (sum(len(speech.split()) for speech in label_speeches)) / speech_freq[value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed  303108 sentences, applying 303108 labels.\n",
      "\n",
      "Approximately many sentences of text per president?\n",
      "0  : Barack Obama         \t46115\n",
      "1  : Donald J. Trump      \t7436\n",
      "2  : Dwight D. Eisenhower \t30381\n",
      "3  : Franklin D. Roosevelt \t26401\n",
      "4  : George Bush          \t24820\n",
      "5  : George W. Bush       \t22448\n",
      "6  : Gerald R. Ford       \t7455\n",
      "7  : Harry S. Truman      \t43005\n",
      "8  : Herbert Hoover       \t7595\n",
      "9  : Jimmy Carter         \t12174\n",
      "10 : John F. Kennedy      \t12436\n",
      "11 : Lyndon B. Johnson    \t25931\n",
      "12 : Richard Nixon        \t8379\n",
      "13 : Ronald Reagan        \t10544\n",
      "14 : William J. Clinton   \t17988\n",
      "\n",
      "Summary stats of sentence counts\n",
      "DescribeResult(nobs=15, minmax=(7436, 46115), mean=20207.200000000001, variance=159986167.02857143, skewness=0.7711964435384968, kurtosis=-0.4618739369874838)\n",
      "\n",
      "Maximum sentence length (characters) =  1364\n",
      "And throughout this process, based on hours of meetingsif you tallied it up, days or weeks of meetings where we went through every option in painful detail, with maps, and we had our military, and we had our aid agencies, and we had our diplomatic teams, and sometimes, we'd bring in outsiders who were critics of ourswhenever we went through it, the challenge was that, short of putting large numbers of U.S. troops on the ground, uninvited, without any international law mandate, without sufficient support from Congress, at a time when we still had troops in Afghanistan and we still had troops in Iraq and we had just gone through over a decade of war and spent trillions of dollars, and when the opposition on the ground was not cohesive enough to necessarily govern a country, and you had a military superpower in Russia prepared to do whatever it took to keep its client state involved, and you had a regional military power in Iran that saw their own vital strategic interests at stake and were willing to send in as many of their people or proxies to support the regimethat in that circumstance, unless we were all in and willing to take over Syria, we were going to have problems, and that everything else was tempting because we wanted to do something and it sounded like the right thing to do, but it was going to be impossible to do this on the cheap.\n"
     ]
    }
   ],
   "source": [
    "import nltk.data\n",
    "from scipy import stats\n",
    "\n",
    "# parse speeches into sentences and see what we have\n",
    "input_text = []\n",
    "input_labels = []\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "for idx in range(0,len(loaded_text)):\n",
    "    speech = loaded_text[idx]\n",
    "    label = loaded_labels[idx]\n",
    "    parsed_sentences = sent_detector.tokenize(speech.strip())\n",
    "    input_text = input_text + parsed_sentences\n",
    "    input_labels = input_labels + ([label]*len(parsed_sentences))\n",
    "\n",
    "print \"Parsed \", len(input_text), \"sentences, applying\", len(input_labels), \"labels.\"\n",
    "\n",
    "print \"\\nApproximately many sentences of text per president?\"\n",
    "sentence_label_count = np.bincount(input_labels)\n",
    "for key, value in sorted(labels.iteritems()):\n",
    "    print str(value).ljust(2), \":\", key.ljust(20), \"\\t\", sentence_label_count[value]\n",
    "\n",
    "print \"\\nSummary stats of sentence counts\"\n",
    "print stats.describe(sentence_label_count)\n",
    "\n",
    "max_sentence_len = len(max(input_text, key=len))\n",
    "print \"\\nMaximum sentence length (characters) = \", max_sentence_len\n",
    "print max(input_text, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/keras_tf/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared training ( 242486 records) and test ( 60622 records) data sets.\n"
     ]
    }
   ],
   "source": [
    "## USE NLTK Tokenizer instead?\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "max_words = 15000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True, split=\" \", char_level=False)\n",
    "tokenizer.fit_on_texts(input_text)\n",
    "tk_test = tokenizer.texts_to_sequences(input_text)\n",
    "\n",
    "X = sequence.pad_sequences(tk_test, maxlen=max_sentence_len)\n",
    "y = to_categorical(input_labels)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.8, random_state=45)\n",
    "\n",
    "print \"Prepared training (\", len(train_X), \"records) and test (\", len(test_X), \"records) data sets.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1364, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1364, 100)         0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                1515      \n",
      "=================================================================\n",
      "Total params: 2,021,615\n",
      "Trainable params: 2,021,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/keras_tf/lib/python2.7/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 36480/242486 [===>..........................] - ETA: 3171s - loss: 2.4415 - categorical_accuracy: 0.2275"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, SimpleRNN, Dropout\n",
    "\n",
    "max_features = 20000\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 100, input_length=max_sentence_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(100))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adagrad',metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(train_X, y=train_y, batch_size=40, nb_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate performance\n",
    "print \"Evaluating test data...\"\n",
    "loss_and_metrics = model.evaluate(test_X, test_y)\n",
    "\n",
    "# Make some predictions\n",
    "print \"\\nPredicting using test data...\"\n",
    "pred_y = model.predict(test_X, batch_size=100)\n",
    "pred_y_collapsed = np.argmax(pred_y, axis=1)\n",
    "test_y_collapsed = np.argmax(test_y, axis=1)\n",
    "\n",
    "#print pred_y_collapsed, test_y_collapsed\n",
    "\n",
    "print model.metrics_names\n",
    "print loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scikit-learn examples @\n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html \n",
    "%matplotlib inline\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_y_collapsed, pred_y_collapsed)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=(sorted(labels, key=labels.get)),\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=(sorted(labels, key=labels.get)), normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
