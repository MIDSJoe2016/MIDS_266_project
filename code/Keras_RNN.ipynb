{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 1500, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1500, 100)         0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_12 (SimpleRNN)    (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,020,403\n",
      "Trainable params: 2,020,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 34 samples, validate on 9 samples\n",
      "Epoch 1/10\n",
      "1s - loss: 1.1026 - categorical_accuracy: 0.3824 - val_loss: 1.2985 - val_categorical_accuracy: 0.2222\n",
      "Epoch 2/10\n",
      "0s - loss: 1.0540 - categorical_accuracy: 0.3235 - val_loss: 1.3339 - val_categorical_accuracy: 0.2222\n",
      "Epoch 3/10\n",
      "0s - loss: 1.0334 - categorical_accuracy: 0.5588 - val_loss: 1.3737 - val_categorical_accuracy: 0.1111\n",
      "Epoch 4/10\n",
      "0s - loss: 1.0023 - categorical_accuracy: 0.5294 - val_loss: 1.3799 - val_categorical_accuracy: 0.1111\n",
      "Epoch 5/10\n",
      "0s - loss: 0.9793 - categorical_accuracy: 0.5882 - val_loss: 1.3583 - val_categorical_accuracy: 0.1111\n",
      "Epoch 6/10\n",
      "0s - loss: 0.9577 - categorical_accuracy: 0.6176 - val_loss: 1.3715 - val_categorical_accuracy: 0.1111\n",
      "Epoch 7/10\n",
      "0s - loss: 0.9377 - categorical_accuracy: 0.6176 - val_loss: 1.3637 - val_categorical_accuracy: 0.1111\n",
      "Epoch 8/10\n",
      "0s - loss: 0.9171 - categorical_accuracy: 0.6471 - val_loss: 1.3391 - val_categorical_accuracy: 0.1111\n",
      "Epoch 9/10\n",
      "0s - loss: 0.8988 - categorical_accuracy: 0.8235 - val_loss: 1.3597 - val_categorical_accuracy: 0.1111\n",
      "Epoch 10/10\n",
      "0s - loss: 0.8661 - categorical_accuracy: 0.8529 - val_loss: 1.3026 - val_categorical_accuracy: 0.1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13cb837d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#requires NLTK, BeautifulSoup\n",
    "import load_data\n",
    "\n",
    "import glob, os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Embedding, SimpleRNN, Dropout\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "labels = {\"Obama\" : 0, \"Lincoln\": 1, \"Trump\": 2}\n",
    "input_text = []\n",
    "input_labels = []\n",
    "directory = \"../data/processed/\"\n",
    "\n",
    "for filename in glob.glob(os.path.join(directory, '*.txt')):\n",
    "    arr = filename.replace(directory,'').split(\"_\")\n",
    "    input_labels = input_labels + [labels[arr[0]]]\n",
    "    input_text = input_text + [open(filename).read().decode(\"UTF-8\").encode(\"ascii\",\"ignore\")] \n",
    "        \n",
    "tokenizer = Tokenizer(num_words=1000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True, split=\" \", char_level=False)\n",
    "tokenizer.fit_on_texts(input_text)\n",
    "tk_test = tokenizer.texts_to_sequences(input_text)\n",
    "\n",
    "max_len = 1500\n",
    "max_features = 20000\n",
    "\n",
    "x = sequence.pad_sequences(tk_test, maxlen=max_len)\n",
    "y = to_categorical(input_labels)\n",
    "\n",
    "model = Sequential()\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 100, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(SimpleRNN(100))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='SGD',metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x, y=y, batch_size=50, nb_epoch=10, verbose=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
